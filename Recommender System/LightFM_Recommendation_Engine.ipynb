{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ameya-20/BusinessAnalyticsProjects/blob/main/Recommender%20System/LightFM_Recommendation_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JJ2NQ3Nx4W4"
      },
      "source": [
        "# Using LightFM for Recommendations\n",
        "\n",
        "LightFM is a Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback.\n",
        "\n",
        "It also makes it possible to incorporate both item and user metadata into the traditional matrix factorization algorithms. It represents each user and item as the sum of the latent representations of their features, thus allowing recommendations to generalise to new items (via item features) and to new users (via user features).\n",
        "\n",
        "The details of the approach are described in the [LightFM paper](http://arxiv.org/abs/1507.08439).\n",
        "\n",
        "[LightFM](https://lyst.github.io/lightfm/docs/index.html) and it's [documentation](http://lyst.github.io/lightfm/docs/home.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP7obkGAvyTO",
        "outputId": "14df8ac6-6cd3-439d-9b1e-ff0d75e03be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install lightFM, takes around 15 seconds\n",
        "!pip install lightfm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.2.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=804893 sha256=677b50733e586a5eca4fb87c01972151ec457c9a1aeedccd3fbf3ec990aeed29\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mObVypUdyFfz"
      },
      "source": [
        "The first step is to get the Movielens data. This is a classic small recommender dataset, consisting of around 950 users, 1700 movies, and 100,000 ratings. The ratings are on a scale from 1 to 5, but we’ll all treat them as implicit positive feedback in this example.\n",
        "\n",
        "Fortunately, this is one of the functions provided by LightFM itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A2Fptc1vy37"
      },
      "source": [
        "# Import our modules\n",
        "import numpy as np\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm import LightFM"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEEE1vsv4Dp",
        "outputId": "5f84a90a-aeb6-4412-9cdf-736bf4cbcf0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use one of LightFM's inbuild datasets, setting the minimum rating to return at over 4.0\n",
        "data = fetch_movielens(min_rating = 4.0)\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
              " \twith 49906 stored elements in COOrdinate format>,\n",
              " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
              " \twith 5469 stored elements in COOrdinate format>,\n",
              " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
              " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
              " 'item_feature_labels': array(['T', 'G', 'F', ..., 'S', 'Y', 'S'], dtype='<U1'),\n",
              " 'item_labels': array(['T', 'G', 'F', ..., 'S', 'Y', 'S'], dtype='<U1')}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7eXzwwIyAaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78ed8bf-4968-4b58-d6ac-7958f4f9503c"
      },
      "source": [
        "# Get our key and value from our dataset\n",
        "# By printing it, we see it's comprised of a data segments containing test, train, item_features, item_feature_labels & item_labels\n",
        "for key, value in data.items():\n",
        "    print(key, type(value), value.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train <class 'scipy.sparse._coo.coo_matrix'> (943, 1682)\n",
            "test <class 'scipy.sparse._coo.coo_matrix'> (943, 1682)\n",
            "item_features <class 'scipy.sparse._csr.csr_matrix'> (1682, 1682)\n",
            "item_feature_labels <class 'numpy.ndarray'> (1682,)\n",
            "item_labels <class 'numpy.ndarray'> (1682,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slPJ4hn_yNOj",
        "outputId": "cc2ced92-da7f-4cf8-eb37-a62359a96ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# What type of data are we working with? coo_matrix\n",
        "type(data['train'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._coo.coo_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqBntxy9zHaF",
        "outputId": "e2f5060c-b8d1-40ef-e127-89e5254d7c9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Each row represents a user, and each column an item.\n",
        "# We use .tocsr() to view it as a Compressed Sparse Row format, it's an inbuilt function in the coo_matrix object\n",
        "m1 = data['train'].tocsr()\n",
        "\n",
        "print(m1[0,0])\n",
        "print(m1[0,1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcE4UE4Bytto"
      },
      "source": [
        "**coo_matrix - A sparse matrix in COOrdinate format - Intended Usage:**\n",
        "\n",
        "- COO is a fast format for constructing sparse matrices\n",
        "- Once a matrix has been constructed, convert to CSR or CSC format for fast arithmetic and matrix vector operations\n",
        "- By default when converting to CSR or CSC format, duplicate (i,j) entries will be summed together.  This facilitates efficient construction of finite element matrices and the like. (see example)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-ygYGxIv4O8",
        "outputId": "20c5f84b-fe62-4787-e30c-624e4db44f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(repr(data['train'])) # rept() is used in debugging to get a string representation of object\n",
        "print(repr(data['test']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 49906 stored elements in COOrdinate format>\n",
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 5469 stored elements in COOrdinate format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoGJfN120J5Q"
      },
      "source": [
        "# Let's now create and train our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYbDfvRM8I5f"
      },
      "source": [
        "**Four loss functions are available:**\n",
        "\n",
        "- **logistic**: useful when both positive (1) and negative (-1) interactions are present.\n",
        "- **BPR**: Bayesian Personalised Ranking pairwise loss. Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.\n",
        "- **WARP**: Weighted Approximate-Rank Pairwise loss. Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired.\n",
        "- **k-OS WARP**: k-th order statistic loss. A modification of WARP that uses the k-th positive example for any given user as a basis for pairwise updates.\n",
        "\n",
        "**Two learning rate schedules are available:**\n",
        "- adagrad\n",
        "- adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_wQ4_WEv5VB"
      },
      "source": [
        "# Creat our model object from LightFM\n",
        "# We specify the loss type to be WARP (Weighted Approximate-Rank Pairwise )\n",
        "model = LightFM(loss = 'warp')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJV2VOCav9zS"
      },
      "source": [
        "# Extract our training and test datasets\n",
        "train = data['train']\n",
        "test = data['test']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jemcXW9g9kne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee421df-4799-413c-fb1c-cd75217834a9"
      },
      "source": [
        "# Fit our model over 10 epochs\n",
        "model.fit(train, epochs=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7eda7ffcf070>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spfITtcp-By2"
      },
      "source": [
        "# Performance Evaluation\n",
        "\n",
        "We use Precision and AUC to avaluate our model performance.\n",
        "\n",
        "**The ROC AUC metric for a model**: the probability that a randomly chosen positive example has a higher score than a randomly chosen negative example. A perfect score is 1.0.\n",
        "\n",
        "**The precision at k metric for a model**: the fraction of known positives in the first k positions of the ranked list of results. A perfect score is 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcD9wDSzzbCQ",
        "outputId": "724b628d-3ea7-4d12-942a-5b577620628f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate it's performance\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.evaluation import auc_score\n",
        "\n",
        "train_precision = precision_at_k(model, train, k=10).mean()\n",
        "test_precision = precision_at_k(model, test, k=10).mean()\n",
        "\n",
        "train_auc = auc_score(model, train).mean()\n",
        "test_auc = auc_score(model, test).mean()\n",
        "\n",
        "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
        "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: train 0.48, test 0.08.\n",
            "AUC: train 0.94, test 0.91.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRXeCHXG03GU"
      },
      "source": [
        "We got\n",
        "# Let's see what movies are recommended for some users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvC-B4rIv_Ka"
      },
      "source": [
        "# Function credit goes to Arun Mathew Kurian\n",
        "# Let's test it out and see how well it works\n",
        "def sample_recommendation(model, data, user_ids):\n",
        "    '''uses model, data and a list of users ideas and outputs the recommended movies along with known positives for each user'''\n",
        "    n_users, n_items = data['train'].shape\n",
        "    for user_id in user_ids:\n",
        "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
        "\n",
        "        scores = model.predict(user_id, np.arange(n_items))\n",
        "\n",
        "        top_items = data['item_labels'][np.argsort(-scores)]\n",
        "\n",
        "        print(\"User %s\" % user_id)\n",
        "        print(\"Known positives:\")\n",
        "\n",
        "        # Print the first 3 known positives\n",
        "        for x in known_positives[:3]:\n",
        "            print(\"%s\" % x)\n",
        "\n",
        "        # Print the first 3 recommended movies\n",
        "        print(\"Recommended:\")\n",
        "        for x in top_items[:3]:\n",
        "            print(\"%s\" % x)\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IasvcwZ9wbUf",
        "outputId": "7b710915-54fb-48fe-a292-0b4e2c56cff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testing on users 6, 125 and 336\n",
        "sample_recommendation(model, data, [6, 125, 336])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 6\n",
            "Known positives:\n",
            "G\n",
            "T\n",
            "B\n",
            "Recommended:\n",
            "R\n",
            "S\n",
            "A\n",
            "\n",
            "\n",
            "User 125\n",
            "Known positives:\n",
            "J\n",
            "K\n",
            "S\n",
            "Recommended:\n",
            "E\n",
            "L\n",
            "A\n",
            "\n",
            "\n",
            "User 336\n",
            "Known positives:\n",
            "M\n",
            "S\n",
            "A\n",
            "Recommended:\n",
            "R\n",
            "S\n",
            "I\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpao0Fmi0TcX"
      },
      "source": [
        "### Other LightFM Datasets.\n",
        "\n",
        "https://lyst.github.io/lightfm/docs/examples/dataset.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPjnLIBzyBcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}